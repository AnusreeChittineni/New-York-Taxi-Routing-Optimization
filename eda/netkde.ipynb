{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f369e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import duckdb\n",
    "from duckdb.typing import DOUBLE, INTEGER, VARCHAR\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22d51cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAXI_DUCKDB_PATH = \"../nyc_traffic_2016.duckdb\"\n",
    "\n",
    "con = duckdb.connect(TAXI_DUCKDB_PATH, read_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd19258b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌───────────────────────────────┐\n",
       "│ average_trip_duration_seconds │\n",
       "│            double             │\n",
       "├───────────────────────────────┤\n",
       "│             969.5513397498753 │\n",
       "└───────────────────────────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.query(\"\"\"SELECT\n",
    "    AVG(\n",
    "        EXTRACT(EPOCH FROM (\n",
    "            CAST(dropoff_datetime AS TIMESTAMP) \n",
    "            - \n",
    "            CAST(pickup_datetime AS TIMESTAMP)\n",
    "            ))\n",
    "        ) AS average_trip_duration_seconds\n",
    "        FROM\n",
    "          taxi_data;\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04da2b01",
   "metadata": {},
   "source": [
    "So the average time period is about 15 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fce5ab",
   "metadata": {},
   "source": [
    "## Slice By Hour of the Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3882d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_of_day_slices(con, start_time, end_time, start_dt_column_name, end_dt_column_name, table_name, slice_minutes=15):\n",
    "    \"\"\"\n",
    "    Generates slices of the total taxi trip dataset, each of which represent the trips whose durations overlap a given 15 minute window\n",
    "    of time of day.\n",
    "    For example, if the window is 8:30 AM to 8:45 AM, a trip which started at 8:30 but has an end time of 8:35 would be included.\n",
    "\n",
    "    Args:\n",
    "        con (_duckdb.DuckDBPyConnection): the connection to the duckDB database\n",
    "        start_time (str): The overall start time of the data range.\n",
    "        end_time (str): The overall end time of the data range.\n",
    "        dt_column_name (str): The name of the datetime column in the table.\n",
    "        table_name (str): The name of the table to query.\n",
    "        slice_minutes (int): The size of the time slice in minutes.\n",
    "    \n",
    "    Yields:\n",
    "        df: a dataframe containing all of the trips between two times of day\n",
    "    \"\"\"\n",
    "    start_dt = datetime.strptime(start_time, \"%H:%M\")\n",
    "    end_dt = datetime.strptime(end_time, \"%H:%M\")\n",
    "\n",
    "    current_time = start_dt\n",
    "    \n",
    "    # Ensure the loop runs until the current time slice is fully processed\n",
    "    while current_time < end_dt:\n",
    "        slice_end_time = current_time + timedelta(minutes=slice_minutes)\n",
    "        \n",
    "        # Determine the effective end time for the slice, ensuring it doesn't \n",
    "        # exceed the overall end_dt\n",
    "        effective_end_time = min(slice_end_time, end_dt)\n",
    "        \n",
    "        # 1. Format datetimes as strings for SQL (ISO 8601 is generally safe)\n",
    "        start_str = current_time.strftime('%H:%M:%S')\n",
    "        end_str = effective_end_time.strftime('%H:%M:%S')\n",
    "\n",
    "        # 2. Construct the SQL query\n",
    "        # Use >= start and < end to ensure non-overlapping, contiguous slices\n",
    "        sql_query = f\"\"\"\n",
    "            SELECT pickup_longitude, pickup_latitude, dropoff_longitude, dropoff_latitude\n",
    "            FROM {table_name}\n",
    "            WHERE CAST({start_dt_column_name} as TIME) >= '{start_str}'\n",
    "              AND CAST({end_dt_column_name} as TIME) < '{end_str}';\n",
    "        \"\"\"\n",
    "        df = con.query(sql_query).df()\n",
    "\n",
    "        yield (start_str, end_str, df)\n",
    "        \n",
    "        # Move to the next slice\n",
    "        current_time = effective_end_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ad72b4",
   "metadata": {},
   "source": [
    "## Get Manhattan Node Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44780dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "# download the Manhattan road network\n",
    "place = \"Manhattan, New York City, USA\"\n",
    "G = ox.graph_from_place(place, network_type=\"drive\")\n",
    "\n",
    "# project the graph\n",
    "G_proj = ox.project_graph(G)\n",
    "\n",
    "# gt the geodataframe of nodes\n",
    "nodes_gdf = ox.graph_to_gdfs(G_proj, edges=False)\n",
    "target_crs = G_proj.graph['crs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7825f3",
   "metadata": {},
   "source": [
    "### Create Manhattan Boundary and Select Trips within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb096bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_boundary = gpd.read_file(\"geo/nyc_boroughs.json\")\n",
    "manhattan_bound = nyc_boundary[nyc_boundary['BoroName'] == \"Manhattan\"].union_all()\n",
    "manhattan_gdf = gpd.GeoDataFrame(geometry=[manhattan_bound], crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58c13f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_points_within_mask(boundary_gdf, points):\n",
    "    \"\"\"\n",
    "    Returns a mask of equal length to the input array of points, with True indicating that the point is within the polygon\n",
    "    described by boundary and False indicating that it is not.\n",
    "\n",
    "    boundary (gpd.GeoDataFrame): boundary describing which points you want to keep\n",
    "    points (GeoDataFrame): GeoDataFrame containing the points to filter\n",
    "\n",
    "    Returns:\n",
    "    pd.Series: a mask of equal length to the input array describing which points are within the geometry\n",
    "    \"\"\"\n",
    "\n",
    "    if points.crs != boundary_gdf.crs:\n",
    "        boundary_gdf = boundary_gdf.to_crs(points.crs) # reproject points to boundary\n",
    "\n",
    "    merged = gpd.sjoin(\n",
    "        left_df=points,\n",
    "        right_df=boundary_gdf,\n",
    "        how='left',\n",
    "        predicate='within' \n",
    "    )\n",
    "\n",
    "    mask = merged['index_right'].notna()\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_trips_within(boundary, trips):\n",
    "    \"\"\"\n",
    "    Returns an updated GeoDataFrame with trips filtered for whether or not both their start and end points are within the\n",
    "    geography provided by boundary.\n",
    "\n",
    "    boundary (gpd.GeoDataFrame): boundary describing which points you want to keep\n",
    "    trips (gpd.GeoDataFrame): GeoDataFrame containing trips, namely with the pickup_longitude, pickup_latitude, \n",
    "    dropoff_longitude, dropoff_latitude columns\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: a dataframe containing a subset of the inputted trips, which have their start and end points both within the geometry\n",
    "    \"\"\"\n",
    "\n",
    "    pickup_points = gpd.GeoDataFrame(\n",
    "        trips.copy(),\n",
    "        geometry=gpd.points_from_xy(\n",
    "            x=trips['pickup_longitude'], \n",
    "            y=trips['pickup_latitude']\n",
    "        ),\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "    \n",
    "    dropoff_points = gpd.GeoDataFrame(\n",
    "        trips.copy(),\n",
    "        geometry=gpd.points_from_xy(\n",
    "            x=trips['dropoff_longitude'], \n",
    "            y=trips['dropoff_latitude']\n",
    "        ),\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "    \n",
    "    # use the dummy point dfs to generate masks\n",
    "    pickup_mask = get_points_within_mask(boundary, pickup_points)\n",
    "    dropoff_mask = get_points_within_mask(boundary, dropoff_points)\n",
    "    \n",
    "    combined_mask = pickup_mask & dropoff_mask\n",
    "    \n",
    "    trips_within = trips.loc[combined_mask].copy()\n",
    "    \n",
    "    return trips_within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56347036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_points_to_nodes(graph, points):\n",
    "    \"\"\"\n",
    "    Assigns the points in the provided GeoDataFrame to each of the nodes, returning an array of nodes per point, which can later be appended\n",
    "    to the points dataframe.\n",
    "    graph (networkx.classes.multidigraph.MultiDiGraph): osmnx generated graph containing node representations of street intersections\n",
    "    points (gpd.GeoDataFrame): a series of points\n",
    "\n",
    "    Returns:\n",
    "    pd.Series: series containing the node corresponding to each of the points passed in\n",
    "    \"\"\"\n",
    "\n",
    "    target_crs = graph.graph['crs']\n",
    "\n",
    "    if points.crs != target_crs:\n",
    "        points_proj = points.to_crs(target_crs)\n",
    "    else:\n",
    "        points_proj = points\n",
    "\n",
    "    projected_x = points_proj.geometry.x.tolist()\n",
    "    projected_y = points_proj.geometry.y.tolist()\n",
    "    \n",
    "    nearest_node_ids = ox.nearest_nodes(\n",
    "        graph,\n",
    "        X=projected_x, \n",
    "        Y=projected_y\n",
    "    )\n",
    "\n",
    "    return pd.Series(nearest_node_ids, index=points.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b2c6c4",
   "metadata": {},
   "source": [
    "## Collect Unique Node Combos in the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "230cbad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_gen = generate_time_of_day_slices(con, \"08:00\", \"09:00\", 'pickup_datetime', 'dropoff_datetime', 'taxi_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05441540",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_pairs_list = []\n",
    "node_pair_counts = {}\n",
    "\n",
    "for start, end, slice in slice_gen:\n",
    "    within = get_trips_within(manhattan_gdf, slice)\n",
    "\n",
    "    pickup_gdf = gpd.GeoDataFrame(\n",
    "        within,\n",
    "        geometry=gpd.points_from_xy(\n",
    "            x=within['pickup_longitude'], \n",
    "            y=within['pickup_latitude']\n",
    "        ),\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "\n",
    "    dropoff_gdf = gpd.GeoDataFrame(\n",
    "        within,\n",
    "        geometry=gpd.points_from_xy(\n",
    "            x=within['dropoff_longitude'], \n",
    "            y=within['dropoff_latitude']\n",
    "        ),\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "\n",
    "    pickup_nodes = assign_points_to_nodes(G_proj, pickup_gdf)\n",
    "    dropoff_nodes = assign_points_to_nodes(G_proj, dropoff_gdf)\n",
    "\n",
    "    within['pickup_node'] = pickup_nodes\n",
    "    within['dropoff_node'] = dropoff_nodes\n",
    "\n",
    "    node_pairs = within[['pickup_node', 'dropoff_node']]\n",
    "    unique_routes = node_pairs.drop_duplicates()\n",
    "    \n",
    "    node_pairs_list.append(unique_routes)\n",
    "    node_pair_counts[start + \"-\" + end] = node_pairs.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "096a5bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_node_pairs = pd.concat(node_pairs_list)\n",
    "unique_node_pairs = unique_node_pairs.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37fcef87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(693776, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_node_pairs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0261623",
   "metadata": {},
   "source": [
    "There are around 630 thousand routes which we need to route."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60f422d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'08:15:0008:30:00': pickup_node  dropoff_node\n",
       " 42422026     42433712        117\n",
       " 42439440     42429876        104\n",
       " 42422026     42433715         91\n",
       " 42435422     42429876         88\n",
       " 42446849     42436060         85\n",
       "                             ... \n",
       " 42435680     42450341          1\n",
       "              42450290          1\n",
       "              42450057          1\n",
       "              42450055          1\n",
       "              42452117          1\n",
       " Name: count, Length: 460460, dtype: int64,\n",
       " '08:30:0008:45:00': pickup_node  dropoff_node\n",
       " 42435422     42445867        103\n",
       " 42439440     42429876         91\n",
       " 4443775465   42430597         85\n",
       " 42439840     42435598         81\n",
       " 42434268     5849918502       70\n",
       "                             ... \n",
       " 13324038870  42443807          1\n",
       "              42445001          1\n",
       "              42437058          1\n",
       "              42437914          1\n",
       "              42438506          1\n",
       " Name: count, Length: 457539, dtype: int64,\n",
       " '08:45:0009:00:00': pickup_node  dropoff_node\n",
       " 42446849     42436060        127\n",
       "              12416643515      91\n",
       " 42435714     42430745         90\n",
       " 42435422     42445867         87\n",
       "              42429876         70\n",
       "                             ... \n",
       " 13324038870  42436486          1\n",
       "              42436590          1\n",
       "              42436939          1\n",
       "              42437050          1\n",
       "              42437058          1\n",
       " Name: count, Length: 475581, dtype: int64}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_pair_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7496d20d",
   "metadata": {},
   "source": [
    "## Calculate the Routes and Identify the Number of Times Each Node Appears per Time Slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a99ac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_proj = ox.add_edge_speeds(G_proj)\n",
    "G_proj = ox.add_edge_travel_times(G_proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b74e97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "\n",
    "def aggregate_node_visitations(G_proj, route_frequencies, weight_metric=\"travel_time\"):\n",
    "    \"\"\"\n",
    "    Finds the shortest path for each unique O-D pair and aggregates the total \n",
    "    visitation count for every node in the graph, including duplicates.\n",
    "    \"\"\"\n",
    "    \n",
    "    node_visitation_counts = collections.defaultdict(int)\n",
    "\n",
    "    total_count = 0\n",
    "    total_missed = 0\n",
    "    # iterate through the unique routes and their frequencies\n",
    "    for (u, v), trip_count in tqdm(route_frequencies.items(), total=route_frequencies.shape[0]):\n",
    "        total_count += trip_count\n",
    "        try:\n",
    "            # find the shortest path (list of node IDs) between the O-D pair\n",
    "            route_nodes = nx.shortest_path(\n",
    "                G_proj,\n",
    "                source=u,\n",
    "                target=v,\n",
    "                weight=weight_metric\n",
    "            )\n",
    "\n",
    "            # for each node in the route, add the number of times the trip appears to the final node_visitation count\n",
    "            for node_id in route_nodes:\n",
    "                node_visitation_counts[node_id] += trip_count\n",
    "                \n",
    "        except nx.NetworkXNoPath:\n",
    "            # Handle cases where no route can be found\n",
    "            # print(f\"Warning: No path found between node {u} and {v}. Skipping.\")\n",
    "            total_missed += trip_count\n",
    "    \n",
    "    print(f\"Missed: {total_missed / total_count * 100}%\")\n",
    "    count_series = pd.Series(node_visitation_counts, name=\"count\")\n",
    "    \n",
    "    return count_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "23336044",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_projected = nodes_gdf.to_crs(\"EPSG:4326\")\n",
    "nodes_projected['x'] = nodes_projected.geometry.x\n",
    "nodes_projected['y'] = nodes_projected.geometry.y\n",
    "nodes_coords = nodes_projected[['x', 'y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b2c7cd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455158/455158 [31:08<00:00, 243.63it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missed: 0.08968018887483506%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'collections.defaultdict' object has no attribute 'to_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m time_period, pair_counts \u001b[38;5;129;01min\u001b[39;00m node_pair_counts\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      2\u001b[0m     node_counts \u001b[38;5;241m=\u001b[39m aggregate_node_visitations(G_proj, pair_counts, weight_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtravel_time\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     node_counts_df \u001b[38;5;241m=\u001b[39m \u001b[43mnode_counts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_frame\u001b[49m()\n\u001b[1;32m      5\u001b[0m     node_count_w_coords_df \u001b[38;5;241m=\u001b[39m node_counts_df\u001b[38;5;241m.\u001b[39mjoin(nodes_coords, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m     node_count_w_coords_df\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'collections.defaultdict' object has no attribute 'to_frame'"
     ]
    }
   ],
   "source": [
    "for time_period, pair_counts in node_pair_counts.items():\n",
    "    node_counts = aggregate_node_visitations(G_proj, pair_counts, weight_metric=\"travel_time\")\n",
    "    node_counts_df = node_counts.to_frame()\n",
    "\n",
    "    node_count_w_coords_df = node_counts_df.join(nodes_coords, how='left')\n",
    "    node_count_w_coords_df.head()\n",
    "\n",
    "    node_counts.to_csv(f\"out/node_counts_{time_period}.csv\", header=True)\n",
    "\n",
    "    with open(f\"out/node_events_{time_period}.txt\", \"w+\") as out:\n",
    "        for i, row in node_count_w_coords_df.iterrows():\n",
    "            out.writelines([f\"{row['x']} {row['y']}\\n\"] * int(row['count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "98b178e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/hice1/tpeng49/.conda/envs/pynkdv/lib/python310.zip',\n",
       " '/home/hice1/tpeng49/.conda/envs/pynkdv/lib/python3.10',\n",
       " '/home/hice1/tpeng49/.conda/envs/pynkdv/lib/python3.10/lib-dynload',\n",
       " '',\n",
       " '/home/hice1/tpeng49/.conda/envs/pynkdv/lib/python3.10/site-packages']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b91ff5e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nkdv_C_library' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpynkdv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mPyNKDV\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m setPath([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/hice1/tpeng49/.conda/envs/pynkdv/lib/python310.zip\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/hice1/tpeng49/.conda/envs/pynkdv/lib/python3.10\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/hice1/tpeng49/.conda/envs/pynkdv/lib/python3.10/lib-dynload\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/hice1/tpeng49/.conda/envs/pynkdv/lib/python3.10/site-packages\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      9\u001b[0m node_data \u001b[38;5;241m=\u001b[39m map_road_network(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout/test.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/pynkdv/lib/python3.10/site-packages/pynkdv/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpynkdv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mPyNKDV\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/pynkdv/lib/python3.10/site-packages/pynkdv/PyNKDV.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnkdv\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mosmnx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mox\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/pynkdv/lib/python3.10/site-packages/nkdv/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnkdv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NKDV\n",
      "File \u001b[0;32m~/.conda/envs/pynkdv/lib/python3.10/site-packages/nkdv/nkdv.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompute_nkdv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compute_nkdv\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mNKDV\u001b[39;00m:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,out_name \u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,method\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,lixel_reg_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,kernel_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,bandwidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n",
      "File \u001b[0;32m~/.conda/envs/pynkdv/lib/python3.10/site-packages/nkdv/compute_nkdv.py:57\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m nkdv \u001b[38;5;241m=\u001b[39m \u001b[43mnkdv_C_library\u001b[49m\u001b[38;5;241m.\u001b[39mnkdv\n\u001b[1;32m     58\u001b[0m nkdv\u001b[38;5;241m.\u001b[39margtypes \u001b[38;5;241m=\u001b[39m (ctypes\u001b[38;5;241m.\u001b[39mc_int,ctypes\u001b[38;5;241m.\u001b[39mPOINTER(ctypes\u001b[38;5;241m.\u001b[39mc_char_p))\n\u001b[1;32m     59\u001b[0m nkdv\u001b[38;5;241m.\u001b[39mrestype \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_char_p\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nkdv_C_library' is not defined"
     ]
    }
   ],
   "source": [
    "from pynkdv.PyNKDV import *\n",
    "\n",
    "setPath(['/home/hice1/tpeng49/.conda/envs/pynkdv/lib/python310.zip',\n",
    " '/home/hice1/tpeng49/.conda/envs/pynkdv/lib/python3.10',\n",
    " '/home/hice1/tpeng49/.conda/envs/pynkdv/lib/python3.10/lib-dynload',\n",
    " '',\n",
    " '/home/hice1/tpeng49/.conda/envs/pynkdv/lib/python3.10/site-packages'])\n",
    "\n",
    "node_data = map_road_network(f\"out/test.txt\")\n",
    "model = PyNKDV(node_data, bandwidth=1000, lixel_size=5, num_threads=8)\n",
    "results = model.compute()\n",
    "output(results, f\"test_nkde.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4f8eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynkdv.PyNKDV import *\n",
    "\n",
    "for key in node_pair_counts.keys():\n",
    "    node_data = map_road_network(f\"out/node_events_{key}.txt\")\n",
    "    model = PyNKDV(node_data, bandwidth=1000, lixel_size=5, num_threads=8)\n",
    "    results = model.compute()\n",
    "    output(results, f\"{key}_nkde.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ef2879",
   "metadata": {},
   "source": [
    "## Implement NetKDE or PyNKDV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef446502",
   "metadata": {},
   "source": [
    "## Run NetKDE over Road Network"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pynkdv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
